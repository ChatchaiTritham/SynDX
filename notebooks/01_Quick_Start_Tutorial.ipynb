{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SynDX Quick Start Tutorial\n",
    "\n",
    "**⚠️ IMPORTANT NOTICE:**  \n",
    "This is **preliminary work without clinical validation**.  \n",
    "Do **NOT** use for clinical decision-making.  \n",
    "All metrics are based on synthetic-to-synthetic validation only.\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates the basic usage of SynDX framework for generating synthetic vestibular disorder patient data.\n",
    "\n",
    "### What SynDX Does\n",
    "\n",
    "1. **Phase 1**: Extract 8,400 clinical archetypes from TiTrATE guidelines\n",
    "2. **Phase 2**: Generate synthetic patients using XAI-driven synthesis\n",
    "3. **Phase 3**: Validate statistical realism and diagnostic coherence\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "```bash\n",
    "pip install -e .\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "sys.path.append('..')  # Add parent directory to path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Import SynDX modules\n",
    "from syndx import SynDXPipeline\n",
    "from syndx.phase1_knowledge import ArchetypeGenerator, TiTrATEFormalizer\n",
    "from syndx.utils import DataLoader\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✓ Imports successful\")\n",
    "print(\"⚠️  WARNING: Preliminary work without clinical validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initialize SynDX Pipeline\n",
    "\n",
    "Create a pipeline with default parameters:\n",
    "- 100 archetypes (reduced for quick demo)\n",
    "- NMF components: 20\n",
    "- Differential privacy ε = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pipeline with small dataset for quick demo\n",
    "pipeline = SynDXPipeline(\n",
    "    n_archetypes=100,      # Reduced from 8400 for demo\n",
    "    nmf_components=20,\n",
    "    vae_latent_dim=50,\n",
    "    epsilon=1.0,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "print(\"SynDX Pipeline initialized:\")\n",
    "print(f\"  Target archetypes: {pipeline.n_archetypes}\")\n",
    "print(f\"  NMF components (r): {pipeline.nmf_components}\")\n",
    "print(f\"  VAE latent dim (d): {pipeline.vae_latent_dim}\")\n",
    "print(f\"  Privacy budget (ε): {pipeline.epsilon}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Phase 1 - Extract Clinical Archetypes\n",
    "\n",
    "Generate computational archetypes from TiTrATE diagnostic framework:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract archetypes from clinical guidelines\n",
    "archetypes = pipeline.extract_archetypes(\n",
    "    guidelines=['titrate', 'barany_icvd_2025']\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated {len(archetypes)} valid archetypes\")\n",
    "print(f\"Archetype matrix shape: {pipeline.archetype_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Archetype Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get statistics\n",
    "stats = pipeline.archetype_generator.get_statistics()\n",
    "\n",
    "# Plot diagnosis distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Diagnosis distribution\n",
    "dx_dist = pd.Series(stats['diagnosis_distribution']).sort_values(ascending=False)\n",
    "axes[0].bar(range(len(dx_dist)), dx_dist.values)\n",
    "axes[0].set_xticks(range(len(dx_dist)))\n",
    "axes[0].set_xticklabels(dx_dist.index, rotation=45, ha='right')\n",
    "axes[0].set_title('Diagnosis Distribution')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "# Timing distribution\n",
    "timing_dist = pd.Series(stats['timing_distribution'])\n",
    "axes[1].pie(timing_dist.values, labels=timing_dist.index, autopct='%1.1f%%')\n",
    "axes[1].set_title('Timing Pattern Distribution')\n",
    "\n",
    "# Age distribution\n",
    "ages = [arch.age for arch in archetypes]\n",
    "axes[2].hist(ages, bins=20, edgecolor='black', alpha=0.7)\n",
    "axes[2].set_title('Age Distribution')\n",
    "axes[2].set_xlabel('Age (years)')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "axes[2].axvline(stats['age_stats']['mean'], color='red', \n",
    "                linestyle='--', label=f\"Mean: {stats['age_stats']['mean']:.1f}\")\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/archetype_statistics.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAge statistics:\")\n",
    "print(f\"  Mean: {stats['age_stats']['mean']:.1f} years\")\n",
    "print(f\"  Std:  {stats['age_stats']['std']:.1f} years\")\n",
    "print(f\"  Range: {stats['age_stats']['min']}-{stats['age_stats']['max']} years\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Phase 2 - Generate Synthetic Patients\n",
    "\n",
    "Generate 1,000 synthetic patients using XAI-driven synthesis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic patients\n",
    "n_patients = 1000\n",
    "synthetic_patients = pipeline.generate(\n",
    "    n_patients=n_patients,\n",
    "    convergence_threshold=0.05\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated {len(synthetic_patients)} synthetic patients\")\n",
    "print(f\"\\nFirst 5 patients:\")\n",
    "print(synthetic_patients.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Phase 3 - Validate Synthetic Data\n",
    "\n",
    "Compute statistical realism metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate synthetic data\n",
    "validation_results = pipeline.validate(\n",
    "    synthetic_patients,\n",
    "    metrics=['statistical', 'diagnostic', 'xai']\n",
    ")\n",
    "\n",
    "print(\"\\nValidation Results:\")\n",
    "print(\"=\"*60)\n",
    "for metric, value in validation_results.get('statistical', {}).items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{metric:20s}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"{metric:20s}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Export to FHIR Format\n",
    "\n",
    "Export synthetic patients to HL7 FHIR R4 format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path('../outputs/synthetic_patients')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Export to FHIR\n",
    "fhir_path = output_dir / 'synthetic_patients_fhir.json'\n",
    "pipeline.export_fhir(synthetic_patients, str(fhir_path))\n",
    "\n",
    "# Also save as CSV\n",
    "csv_path = output_dir / 'synthetic_patients.csv'\n",
    "synthetic_patients.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"\\nSynthetic patients exported:\")\n",
    "print(f\"  FHIR: {fhir_path}\")\n",
    "print(f\"  CSV:  {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This quick start demonstrated:\n",
    "\n",
    "1. ✓ Initializing SynDX pipeline\n",
    "2. ✓ Extracting clinical archetypes from TiTrATE guidelines\n",
    "3. ✓ Generating synthetic patients\n",
    "4. ✓ Validating statistical realism\n",
    "5. ✓ Exporting to FHIR format\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- See `02_Full_Pipeline_Tutorial.ipynb` for complete 8,400 archetype generation\n",
    "- See `03_Statistical_Validation.ipynb` for detailed validation analysis\n",
    "- See `04_Publication_Figures.ipynb` for high-resolution figures\n",
    "\n",
    "### ⚠️ Important Reminders\n",
    "\n",
    "- **No clinical validation**: All metrics are synthetic-to-synthetic\n",
    "- **Not for clinical use**: This is a research tool only\n",
    "- **Prospective validation required**: Real patient studies needed\n",
    "\n",
    "---\n",
    "\n",
    "**Citation:**\n",
    "\n",
    "```bibtex\n",
    "@article{tritham2025syndx,\n",
    "  title={SynDX: Explainable AI-Driven Synthetic Data Generation},\n",
    "  author={Tritham, Chatchai and Namahoot, Chakkrit Snae},\n",
    "  journal={IEEE Access},\n",
    "  year={2025},\n",
    "  note={Preliminary work without clinical validation}\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
